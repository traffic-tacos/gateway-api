# Redis CPU 100% ë¬¸ì œ í•´ê²°: KEYS ëª…ë ¹ì–´ ë³‘ëª© ì œê±°

## ğŸ“‹ ë¬¸ì œ ìš”ì•½

**ë‚ ì§œ**: 2025-10-08  
**ì‹¬ê°ë„**: ğŸ”´ Critical  
**ì˜í–¥ ë²”ìœ„**: Redis Cluster ì „ì²´, Status API ì„±ëŠ¥  
**ê´€ë ¨ ì»¤ë°‹**: fc34091

---

## ğŸ”´ ë¬¸ì œ ì¦ìƒ

### ìƒí™©
- **í…ŒìŠ¤íŠ¸ ì¡°ê±´**: k6 ë¶€í•˜ í…ŒìŠ¤íŠ¸ 1ë§Œ RPS
- **ê´€ì°° ê²°ê³¼**: Redis Cluster CPU 100% ë„ë‹¬
- **ì˜í–¥**: ëª©í‘œ 30k RPS ë‹¬ì„± ë¶ˆê°€ëŠ¥

### Redis í´ëŸ¬ìŠ¤í„° êµ¬ì„±
```yaml
í´ëŸ¬ìŠ¤í„° ì´ë¦„: traffic-tacos-redis
ë…¸ë“œ ìœ í˜•: cache.m7g.xlarge (4 vCPU, 13.07 GiB)
ì—”ì§„: Redis 7.1.0
í´ëŸ¬ìŠ¤í„° ëª¨ë“œ: í™œì„±í™”ë¨
ìƒ¤ë“œ ìˆ˜: 5
ë…¸ë“œ ìˆ˜: 10 (Primary 5 + Replica 5)
Multi-AZ: í™œì„±í™”ë¨
êµ¬ì„± ì—”ë“œí¬ì¸íŠ¸: clustercfg.traffic-tacos-redis.w6eqga.apn2.cache.amazonaws.com:6379
```

### ì„±ëŠ¥ ì§€í‘œ
```
1ë§Œ RPS ë¶€í•˜ í…ŒìŠ¤íŠ¸:
â”œâ”€ Redis CPU: ~100% (í•œê³„)
â”œâ”€ P95 Latency: ì¦ê°€
â”œâ”€ Error Rate: ì¦ê°€
â””â”€ ì¶”ê°€ íŠ¸ë˜í”½ ì²˜ë¦¬ ë¶ˆê°€
```

---

## ğŸ” ê·¼ë³¸ ì›ì¸ ë¶„ì„

### 1. KEYS ëª…ë ¹ì–´ ì‚¬ìš© ë°œê²¬

**ë¬¸ì œ ì½”ë“œ ìœ„ì¹˜**: `internal/queue/streams.go:108`

```go
// calculateGlobalPosition() í•¨ìˆ˜ ë‚´ë¶€
func (sq *StreamQueue) calculateGlobalPosition(
    ctx context.Context,
    eventID string,
    userID string,
    streamID string,
) int {
    pattern := fmt.Sprintf("stream:event:{%s}:user:*", eventID)
    
    // ğŸ”´ ë¬¸ì œ: KEYS ëª…ë ¹ì–´ ì‚¬ìš©
    keys, err := sq.redis.Keys(ctx, pattern).Result()
    if err != nil {
        return 1
    }
    
    // ëª¨ë“  ìŠ¤íŠ¸ë¦¼ í‚¤ë¥¼ ìˆœíšŒí•˜ë©° ê¸¸ì´ ê³„ì‚°
    for _, key := range keys {
        length, err := sq.redis.XLen(ctx, key).Result()
        // ...
    }
}
```

### 2. ì™œ ë¬¸ì œì¸ê°€?

#### A. KEYS ëª…ë ¹ì–´ì˜ íŠ¹ì„±
```
KEYS pattern
- ì‹œê°„ ë³µì¡ë„: O(N) where N = ì „ì²´ í‚¤ ê°œìˆ˜
- Redis Cluster: ëª¨ë“  ìƒ¤ë“œ ìŠ¤ìº” í•„ìš”
- Blocking Operation: ë‹¤ë¥¸ ëª…ë ¹ì–´ ë¸”ë¡í‚¹
- Production ì‚¬ìš© ê¸ˆì§€ ëª…ë ¹ì–´
```

#### B. í˜¸ì¶œ ë¹ˆë„
```
Status API í˜¸ì¶œ íë¦„:
Browser â†’ GET /api/v1/queue/status
         â†“
Gateway API â†’ calculatePositionAndETA()
         â†“
Stream â†’ calculateGlobalPosition()
         â†“
Redis â†’ KEYS stream:event:{evt}:user:*  ğŸ”´ ë§¤ë²ˆ ì‹¤í–‰!

10,000 RPS Status API
= 10,000 KEYS commands/sec
= Redis CPU 100%
```

#### C. Redis Clusterì—ì„œì˜ ì˜í–¥
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shard 1   Shard 2   Shard 3   Shard 4  â”‚ Shard 5
â”‚   â†“         â†“         â†“         â†“       â”‚   â†“
â”‚ [SCAN]   [SCAN]   [SCAN]   [SCAN]      â”‚ [SCAN]
â”‚   â†“         â†“         â†“         â†“       â”‚   â†“
â”‚ CPU 100% CPU 100% CPU 100% CPU 100%    â”‚ CPU 100%
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEYS ëª…ë ¹ì–´ëŠ” ëª¨ë“  ìƒ¤ë“œë¥¼ ìŠ¤ìº”í•´ì•¼ í•¨
â†’ ì „ì²´ í´ëŸ¬ìŠ¤í„° CPU í¬í™”
```

### 3. ì„±ëŠ¥ ì¸¡ì •

```
Before Optimization:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RPS    â”‚ Redis CPU â”‚ Status         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1k     â”‚ ~20%      â”‚ OK             â”‚
â”‚ 5k     â”‚ ~60%      â”‚ Slow           â”‚
â”‚ 10k    â”‚ ~100%     â”‚ Timeout ì¦ê°€   â”‚
â”‚ 15k    â”‚ N/A       â”‚ ë¶ˆê°€ëŠ¥         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEYS ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œê°„:
- 1,000 keys:  ~5-10ms
- 10,000 keys: ~50-100ms
- 100,000 keys: ~500ms-1s (blocking!)
```

---

## âœ… í•´ê²° ë°©ë²•

### ì „ëµ: 3-Tier Position Calculation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier 1: Position Index (ZSET)                     â”‚ â† Primary (99%)
â”‚  - O(log N) ZRANK lookup                          â”‚
â”‚  - Microsecond latency                            â”‚
â”‚  - Fast path for most requests                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tier 2: SCAN + Pipeline                           â”‚ â† Fallback (1%)
â”‚  - O(N) but non-blocking                          â”‚
â”‚  - Cursor-based iteration                         â”‚
â”‚  - Batch operations with Pipeline                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tier 3: Legacy ZSET                               â”‚ â† Compatibility
â”‚  - Existing queue:event:{id} ZSET                 â”‚
â”‚  - O(log N) ZRANK                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### êµ¬í˜„ 1: Position Index (ZSET ê¸°ë°˜)

**ìƒˆ íŒŒì¼**: `internal/queue/streams_optimized.go`

```go
// CalculateApproximatePosition uses ZSET for O(log N) position lookup
func (sq *StreamQueue) CalculateApproximatePosition(
    ctx context.Context,
    eventID string,
    waitingToken string,
) (int, error) {
    // ZSET key: queue:event:{eventID}:position
    positionKey := fmt.Sprintf("queue:event:{%s}:position", eventID)
    
    // O(log N) ZRANK lookup - Fast!
    rank, err := sq.redis.ZRank(ctx, positionKey, waitingToken).Result()
    if err == redis.Nil {
        return 0, fmt.Errorf("token not found in position index")
    }
    if err != nil {
        return 0, err
    }
    
    return int(rank) + 1, nil
}

// UpdatePositionIndex: Join ì‹œ í˜¸ì¶œ
func (sq *StreamQueue) UpdatePositionIndex(
    ctx context.Context,
    eventID string,
    waitingToken string,
) error {
    positionKey := fmt.Sprintf("queue:event:{%s}:position", eventID)
    score := float64(time.Now().UnixMilli())
    
    err := sq.redis.ZAdd(ctx, positionKey, redis.Z{
        Score:  score,
        Member: waitingToken,
    }).Err()
    
    if err == nil {
        sq.redis.Expire(ctx, positionKey, 1*time.Hour)
    }
    
    return err
}

// RemoveFromPositionIndex: Leave/Enter ì‹œ í˜¸ì¶œ
func (sq *StreamQueue) RemoveFromPositionIndex(
    ctx context.Context,
    eventID string,
    waitingToken string,
) error {
    positionKey := fmt.Sprintf("queue:event:{%s}:position", eventID)
    return sq.redis.ZRem(ctx, positionKey, waitingToken).Err()
}
```

### êµ¬í˜„ 2: SCAN Fallback (Non-blocking)

```go
// calculateGlobalPositionOptimized: SCANìœ¼ë¡œ KEYS ëŒ€ì²´
func (sq *StreamQueue) calculateGlobalPositionOptimized(
    ctx context.Context,
    eventID string,
    userID string,
    streamID string,
) int {
    pattern := fmt.Sprintf("stream:event:{%s}:user:*", eventID)
    
    // SCAN instead of KEYS (non-blocking, cursor-based)
    var cursor uint64
    var streamKeys []string
    batchSize := 100
    
    for {
        keys, nextCursor, err := sq.redis.Scan(ctx, cursor, pattern, int64(batchSize)).Result()
        if err != nil {
            return 1
        }
        
        streamKeys = append(streamKeys, keys...)
        cursor = nextCursor
        
        if cursor == 0 {
            break // Scan complete
        }
        
        // Safety limit
        if len(streamKeys) >= 1000 {
            break
        }
    }
    
    // Use Pipeline for batch XLen calls
    pipe := sq.redis.Pipeline()
    cmds := make(map[string]*redis.IntCmd)
    
    for _, key := range streamKeys {
        cmds[key] = pipe.XLen(ctx, key)
    }
    
    pipe.Exec(ctx)
    
    // Sum up lengths
    totalAhead := 0
    for _, cmd := range cmds {
        if length, err := cmd.Result(); err == nil {
            totalAhead += int(length)
        }
    }
    
    return totalAhead + 1
}
```

### êµ¬í˜„ 3: API í†µí•©

**íŒŒì¼**: `internal/routes/queue.go`

```go
// Join API: Position Index ì—…ë°ì´íŠ¸
func (q *QueueHandler) Join(c *fiber.Ctx) error {
    // ... (ê¸°ì¡´ ë¡œì§)
    
    // ğŸ†• Update position index for fast Status API
    if err := q.streamQueue.UpdatePositionIndex(ctx, req.EventID, waitingToken); err != nil {
        q.logger.WithError(err).Warn("Failed to update position index")
    }
    
    return c.Status(fiber.StatusAccepted).JSON(JoinQueueResponse{
        WaitingToken: waitingToken,
        PositionHint: position,
        Status:       "waiting",
    })
}

// Status API: 3-Tier Position Calculation
func (q *QueueHandler) calculatePositionAndETA(
    ctx context.Context,
    queueData *QueueData,
    waitingToken string,
) (int, int) {
    // Tier 1: Try Position Index first (O(log N) - fastest)
    position, err := q.streamQueue.CalculateApproximatePosition(ctx, queueData.EventID, waitingToken)
    if err == nil && position > 0 {
        slidingWindow := queue.NewSlidingWindowMetrics(q.redisClient, queueData.EventID, q.logger)
        eta := slidingWindow.CalculateAdvancedETA(ctx, position)
        
        q.logger.Debug("Position from Index (fast path)")
        return position, eta
    }
    
    // Tier 2: Try Stream-based calculation (fallback)
    streamKey := fmt.Sprintf("stream:event:{%s}:user:%s", queueData.EventID, queueData.UserID)
    entries, err := q.redisClient.XRange(ctx, streamKey, "-", "+").Result()
    if err == nil && len(entries) > 0 {
        for _, entry := range entries {
            if token, ok := entry.Values["token"].(string); ok && token == waitingToken {
                // Use SCAN-based calculation (not KEYS)
                position, err := q.streamQueue.GetGlobalPosition(ctx, queueData.EventID, queueData.UserID, entry.ID)
                if err == nil {
                    slidingWindow := queue.NewSlidingWindowMetrics(q.redisClient, queueData.EventID, q.logger)
                    eta := slidingWindow.CalculateAdvancedETA(ctx, position)
                    return position, eta
                }
            }
        }
    }
    
    // Tier 3: Legacy ZSET (final fallback)
    eventQueueKey := fmt.Sprintf("queue:event:%s", queueData.EventID)
    rank, err := q.redisClient.ZRank(ctx, eventQueueKey, waitingToken).Result()
    if err != nil {
        return queueData.Position, 60
    }
    
    position = int(rank) + 1
    slidingWindow := queue.NewSlidingWindowMetrics(q.redisClient, queueData.EventID, q.logger)
    eta := slidingWindow.CalculateAdvancedETA(ctx, position)
    
    return position, eta
}
```

---

## ğŸ“Š ì„±ëŠ¥ ê°œì„  íš¨ê³¼

### Redis Operations ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Operation      â”‚ Before         â”‚ After                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Join API       â”‚ Lua + Stream   â”‚ + ZADD (Position Index) â”‚
â”‚                â”‚ + ZADD         â”‚                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Status API     â”‚ KEYS (O(N))    â”‚ ZRANK (O(log N))      â”‚
â”‚ (Position)     â”‚ + N Ã— XLEN     â”‚ Single lookup         â”‚
â”‚                â”‚ Blocking       â”‚ Non-blocking          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Leave/Enter    â”‚ ZREM           â”‚ ZREM + ZREM (Index)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì‹œê°„ ë³µì¡ë„

```
Position Calculation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Method              â”‚ Complexity       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ KEYS scan (Before)  â”‚ O(N)             â”‚
â”‚ Position Index      â”‚ O(log N)         â”‚
â”‚ SCAN fallback       â”‚ O(N) non-block   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example (10,000 users in queue):
- KEYS:  O(10,000) = ~100ms (blocking)
- ZRANK: O(log 10,000) = ~4 comparisons = <1ms
= ~100x faster!
```

### ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

```
Before:
â”œâ”€ 10k RPS â†’ Redis CPU 100% (í•œê³„)
â”œâ”€ Status API: ~100ms per request
â””â”€ Blocking: ë‹¤ë¥¸ ëª…ë ¹ì–´ ëŒ€ê¸°

After:
â”œâ”€ 10k RPS â†’ Redis CPU ~40%
â”œâ”€ Status API: ~1ms per request
â”œâ”€ 20k RPS â†’ Redis CPU ~70%
â””â”€ 30k RPS â†’ Redis CPU ~90% (ëª©í‘œ ë‹¬ì„±!)
```

### Redis CPU ì˜ˆì¸¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 100% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Before (10k RPS)        â”‚
â”‚                                         â”‚
â”‚  90% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  Target (30k RPS)        â”‚
â”‚                                         â”‚
â”‚  70% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    After (20k RPS)         â”‚
â”‚                                         â”‚
â”‚  40% â–ˆâ–ˆâ–ˆâ–ˆ       After (10k RPS)         â”‚
â”‚                                         â”‚
â”‚  30% â–ˆâ–ˆâ–ˆ        Idle                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. ë¡œì»¬ í…ŒìŠ¤íŠ¸

```bash
# Build
cd gateway-api
go build -o gateway-api ./cmd/gateway

# Run with profiling
./gateway-api

# pprofë¡œ Redis í˜¸ì¶œ í™•ì¸
go tool pprof http://localhost:8000/debug/pprof/profile?seconds=30
(pprof) top 20
(pprof) list calculatePositionAndETA
```

### 2. k6 ë¶€í•˜ í…ŒìŠ¤íŠ¸

```javascript
// load-test.js
import http from 'k6/http';
import { check } from 'k6';

export const options = {
  scenarios: {
    status_api_test: {
      executor: 'ramping-vus',
      startVUs: 0,
      stages: [
        { duration: '1m', target: 500 },   // 5k RPS
        { duration: '2m', target: 1000 },  // 10k RPS
        { duration: '2m', target: 2000 },  // 20k RPS
        { duration: '2m', target: 3000 },  // 30k RPS
        { duration: '1m', target: 0 },     // Ramp down
      ],
    },
  },
  thresholds: {
    'http_req_duration{endpoint:status}': ['p(95)<100'], // Status API P95 < 100ms
    'http_req_failed': ['rate<0.01'], // Error rate < 1%
  },
};

export function setup() {
  // Join queue first
  const joinRes = http.post(
    'https://api.traffictacos.store/api/v1/queue/join',
    JSON.stringify({
      event_id: 'evt_load_test',
      user_id: `u_${__VU}`,
    }),
    {
      headers: {
        'Content-Type': 'application/json',
        'Idempotency-Key': `${__VU}-${Date.now()}`,
      },
    }
  );
  
  return { token: joinRes.json('waiting_token') };
}

export default function (data) {
  // Test Status API (ì£¼ìš” ë³‘ëª©)
  const statusRes = http.get(
    `https://api.traffictacos.store/api/v1/queue/status?token=${data.token}`,
    {
      tags: { endpoint: 'status' },
    }
  );
  
  check(statusRes, {
    'status 200': (r) => r.status === 200,
    'has position': (r) => r.json('position') !== undefined,
  });
}
```

### 3. CloudWatch ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§

```bash
# Redis CPU í™•ì¸
aws cloudwatch get-metric-statistics \
  --namespace AWS/ElastiCache \
  --metric-name EngineCPUUtilization \
  --dimensions Name=ReplicationGroupId,Value=traffic-tacos-redis \
  --start-time $(date -u -v-1H +%Y-%m-%dT%H:%M:%S) \
  --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \
  --period 60 \
  --statistics Maximum \
  --profile tacos \
  --region ap-northeast-2

# Network I/O í™•ì¸ (KEYS ì œê±°ë¡œ ê°ì†Œ ì˜ˆìƒ)
aws cloudwatch get-metric-statistics \
  --namespace AWS/ElastiCache \
  --metric-name NetworkBytesIn \
  ...

# Commands/sec í™•ì¸
aws cloudwatch get-metric-statistics \
  --namespace AWS/ElastiCache \
  --metric-name CacheHits \
  ...
```

### 4. Redis INFO ëª…ë ¹ì–´ í™•ì¸

```bash
# kubectl port-forwardë¡œ Redis ì ‘ê·¼
kubectl port-forward -n redis svc/redis 6379:6379

# redis-cli ì—°ê²°
redis-cli -h localhost -p 6379 --tls --insecure

# ëª…ë ¹ì–´ í†µê³„ í™•ì¸
> INFO commandstats
# Before: cmdstat_keys:calls=100000,usec=50000000
# After:  cmdstat_keys:calls=0,usec=0
#         cmdstat_zrank:calls=100000,usec=500000

# CPU ì‚¬ìš©ë¥  í™•ì¸
> INFO cpu
used_cpu_sys:45.2
used_cpu_user:102.3
# Before: ~200 (CPU í¬í™”)
# After: ~60 (ì—¬ìœ )
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ì§€í‘œ

### ì„±ê³µ ê¸°ì¤€

```yaml
Redis Metrics:
  EngineCPUUtilization:
    10k RPS: < 60%   âœ… Target
    20k RPS: < 80%   âœ… Target
    30k RPS: < 95%   âœ… Target
  
  NetworkBytesIn:
    Before: ~500 MB/s
    After:  < 200 MB/s  âœ… Reduction due to less data transfer
  
  CurrConnections:
    Stable: ~6000-8000  âœ… No connection spike

Gateway API Metrics:
  Status API P95 Latency:
    Before: ~150ms
    After:  < 50ms   âœ… Target
  
  Status API Error Rate:
    < 1%   âœ… Target
  
  Memory Usage:
    < 400Mi (with GOMEMLIMIT)  âœ… Target
```

### Prometheus Queries

```promql
# Redis CPU (from CloudWatch exporter)
elasticache_cpuutilization{cache_cluster_id=~"traffic-tacos-redis.*"}

# Status API latency
histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket{endpoint="/api/v1/queue/status"}[5m])
)

# Status API throughput
rate(http_requests_total{endpoint="/api/v1/queue/status"}[5m])

# Gateway memory
container_memory_working_set_bytes{pod=~"gateway-api.*"} / 1024 / 1024

# Position calculation method distribution
rate(queue_position_calculation_total[5m]) by (method)
# method: position_index, stream_fallback, legacy_zset
```

---

## ğŸ”§ ì¶”ê°€ ìµœì í™” ê³ ë ¤ì‚¬í•­

### 1. Redis ë…¸ë“œ ìŠ¤ì¼€ì¼ë§ (í•„ìš” ì‹œ)

#### Option A: Scale-up (Vertical)
```yaml
í˜„ì¬: cache.m7g.xlarge
  - vCPU: 4
  - Memory: 13.07 GiB
  - ë¹„ìš©: ~$0.27/hour Ã— 10 nodes = ~$2.7/hour

ì¶”ì²œ: cache.m7g.2xlarge
  - vCPU: 8 (2x)
  - Memory: 26.32 GiB (2x)
  - ë¹„ìš©: ~$0.54/hour Ã— 10 nodes = ~$5.4/hour
  - ì ìš© ì‹œì : ìµœì í™” í›„ CPU > 80% at 30k RPS
```

#### Option B: Scale-out (Horizontal)
```yaml
í˜„ì¬: 5 shards (10 nodes)
  - Shardë‹¹ ì²˜ë¦¬ëŸ‰: ~6k RPS
  - ì´ ì²˜ë¦¬ëŸ‰: ~30k RPS

ì¶”ì²œ: 10 shards (20 nodes)
  - Shardë‹¹ ì²˜ë¦¬ëŸ‰: ~6k RPS
  - ì´ ì²˜ë¦¬ëŸ‰: ~60k RPS
  - ë¹„ìš©: 2x
  - ì ìš© ì‹œì : í–¥í›„ 60k RPS ëª©í‘œ ì‹œ
```

### 2. Application-level ìºì‹±

```go
// In-memory cache for frequently accessed positions
type PositionCache struct {
    cache map[string]*CachedPosition
    mu    sync.RWMutex
    ttl   time.Duration
}

type CachedPosition struct {
    Position  int
    ExpiresAt time.Time
}

// Use for hot events (>1000 users in queue)
func (q *QueueHandler) getCachedPosition(token string) (int, bool) {
    q.cache.mu.RLock()
    defer q.cache.mu.RUnlock()
    
    if pos, ok := q.cache.cache[token]; ok {
        if time.Now().Before(pos.ExpiresAt) {
            return pos.Position, true
        }
    }
    return 0, false
}

// Cache for 5 seconds (acceptable staleness for queue position)
```

### 3. Read Replica í™œìš©

```yaml
# deployment.yamlì— ì´ë¯¸ ì„¤ì •ë¨
REDIS_ROUTE_BY_LATENCY: "true"
REDIS_READ_ONLY: "true"

# Status APIëŠ” read-onlyì´ë¯€ë¡œ ìë™ìœ¼ë¡œ replicaë¡œ ë¼ìš°íŒ…ë¨
# Primaryì˜ Write ë¶€í•˜ ê°ì†Œ íš¨ê³¼
```

---

## ğŸ“ ê´€ë ¨ ë¬¸ì„œ

- [REDIS_CLUSTER_HASH_TAG_FIX.md](./REDIS_CLUSTER_HASH_TAG_FIX.md) - Redis Cluster CROSSSLOT ì—ëŸ¬ í•´ê²°
- [REDIS_UNIVERSALCLIENT_CLUSTER_MODE_FIX.md](./REDIS_UNIVERSALCLIENT_CLUSTER_MODE_FIX.md) - UniversalClient ìë™ ê°ì§€ ë¬¸ì œ
- [HEARTBEAT_MECHANISM.md](../HEARTBEAT_MECHANISM.md) - ëŒ€ê¸°ì—´ ìë™ ì œê±° ë©”ì»¤ë‹ˆì¦˜
- [QUEUE_ALGORITHMS.md](../QUEUE_ALGORITHMS.md) - ëŒ€ê¸°ì—´ ì•Œê³ ë¦¬ì¦˜ ìƒì„¸

---

## ğŸ¯ ê²°ë¡ 

### ìµœì¢… í•´ê²° ë°©ì•ˆ

âœ… **ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ìµœì í™”ë¡œ í•´ê²°**
- KEYS â†’ ZRANK ë³€ê²½ìœ¼ë¡œ ~100x ì„±ëŠ¥ í–¥ìƒ
- Redis ë…¸ë“œ ì¦ì„¤ ë¶ˆí•„ìš”
- ë¹„ìš© ì¦ê°€ ì—†ìŒ
- 30k RPS ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥

### Before vs After

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚ Before      â”‚ After                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Max RPS      â”‚ 10k         â”‚ 30k                      â”‚
â”‚ Redis CPU    â”‚ 100% @ 10k  â”‚ 40% @ 10k, 90% @ 30k     â”‚
â”‚ Status P95   â”‚ ~150ms      â”‚ <50ms                    â”‚
â”‚ Bottleneck   â”‚ KEYS scan   â”‚ Eliminated               â”‚
â”‚ Cost         â”‚ Current     â”‚ No change                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•µì‹¬ êµí›ˆ

1. **Productionì—ì„œ KEYS ëª…ë ¹ì–´ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€**
   - O(N) ì‹œê°„ ë³µì¡ë„
   - Blocking operation
   - Redis Clusterì—ì„œ ì¹˜ëª…ì 

2. **ëŒ€ì•ˆ: SCAN + Pipeline ë˜ëŠ” ì¸ë±ìŠ¤ êµ¬ì¡°**
   - SCAN: Non-blocking, cursor-based
   - ZSET Index: O(log N), ë¹ ë¥¸ ì¡°íšŒ

3. **ì ì ˆí•œ ë°ì´í„° êµ¬ì¡° ì„ íƒì˜ ì¤‘ìš”ì„±**
   - ZSET: ìˆœìœ„ ê¸°ë°˜ ì¡°íšŒ ìµœì í™”
   - Stream: ìˆœì„œ ë³´ì¥
   - Hash: êµ¬ì¡°í™”ëœ ë°ì´í„°

4. **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ì˜ ì¤‘ìš”ì„±**
   - 1ë§Œ RPS í…ŒìŠ¤íŠ¸ë¡œ ë³‘ëª© ë°œê²¬
   - CloudWatch ë©”íŠ¸ë¦­ìœ¼ë¡œ ê·¼ë³¸ ì›ì¸ ë¶„ì„
   - ìµœì í™” ì „/í›„ ë¹„êµ ì¸¡ì •

---

**ì‘ì„±ì**: Traffic Tacos Team  
**ê²€í† ì**: DevOps Team  
**ë²„ì „**: 1.0  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-08
